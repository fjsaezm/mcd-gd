{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77964e3",
   "metadata": {},
   "source": [
    "*Francisco Javier Sáez Maldonado,\n",
    "José Antonio Álvarez Ocete*\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this assignment, we are asked to create a **data pipeline** using two csv files taken from [MovieLens](http://movielens.ogr). \n",
    "\n",
    "Our goal is to use the available raw data to provide a clean, valid and transformed data that helps the data scientist to obtain information about the data easily. We are told that, after our data pipeline, the following query will be done:\n",
    "\n",
    "> **Obtain a list of movie genres, sorted by their average score\n",
    "> obtained in the last week**.\n",
    "\n",
    "We will orient our code to make this query as easy as possible. We will assume that our data comes in two `.csv` files: `input/movies.csv` and `input/ratings.csv`. We will perform the preprocessing of the data and it will be stored in the folder `output`.\n",
    "\n",
    "Firstly, we will import the needed libraries. `Pandas` will help us to load the *.csv* files and to do the transformations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0dc8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88274a83",
   "metadata": {},
   "source": [
    "Now, we can read the data from the provided *.csv* files and show the first 5 elements of each file, taking a sneak peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e25506",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"input/movies.csv\")\n",
    "ratings = pd.read_csv(\"input/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af19e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2f2672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b85269",
   "metadata": {},
   "source": [
    "As we can see, the data contained in each file is quite different, so we will analyze each part separately and we will try to combine their information at the end to produce the output desired in our query.\n",
    "\n",
    "As a first comment, we must see that in this case the concept of **outliers** does not match to our data. \n",
    "\n",
    "- In the `ratings` dataframe, the *outliers* will be the incorrect ratings or negative times.\n",
    "\n",
    "- In the `movies` dataframe, our outliers will be the invalid genres.\n",
    "\n",
    "\n",
    "Also, **no normalization** is needed in this case. The only possible case of normalization would be to crop the wrong rating values to our interval, but we will take a different approach that will be explained further in this assignment.\n",
    "\n",
    "# Ratings \n",
    "\n",
    "We will begin transforming the input data from this file. Using this data, our goal will be to clean and transform it so that obtaining the rating of each film is as easy as possible.\n",
    "\n",
    "The procedure that we will follow is the is the next one:\n",
    "\n",
    "1. Ignore all the data that was obtained earlier than $1$ week before, since we are only interested in the data of the last week.\n",
    "\n",
    "2. Remove all null and wrong values that we can find in the reduced table.\n",
    "\n",
    "3. Group values by movieId and compute mean rating for each film, storing it on a table.\n",
    "\n",
    "We begin by removing all the data that was introduced a $n\\_weeks$ ago. Our goal is to use only the last week ($n\\_weeks = 1$), but since the data last updated more than 2 years ago, we code a general function that takes the data from the last $n\\_weeks$ and stores it in a dataframe. Using $n\\_weeks$, we are **assuming that the processed data will only be used to perform this query and not other queries**.\n",
    "\n",
    "**In the code example, we will use $120$ weeks, although in the final pipeline a single week will be used. This is done with correctness-showing purposes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216d510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "week = 60*60*24*7\n",
    "filter_date = lambda df, n_weeks = 1 : df[df['timestamp'] > time.time() - n_weeks *week ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e803997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº ratings before removing invalid dates: 25000095\n",
      "Nº ratings after removing invalid dates: 259555\n"
     ]
    }
   ],
   "source": [
    "# Remove invalid dates\n",
    "print(\"Nº ratings before removing invalid dates: {}\".format(len(ratings.index)))\n",
    "ratings_date = filter_date(ratings, 120)\n",
    "print(\"Nº ratings after removing invalid dates: {}\".format(len(ratings_date.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453299f3",
   "metadata": {},
   "source": [
    "We have already removed the data that, by timedate, is not usefull for us. Now, we have to remove the incorrect/wrong data. The most basic step is to remove the rows of the dataframe that contain null values and also the columns that are duplicated. We combine this two actions in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c63791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes rows that have a null value\n",
    "remove_nulls = lambda df : df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812a1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº ratings before removing: 259555\n",
      "Nº ratings after removing: 254432\n"
     ]
    }
   ],
   "source": [
    "# Remove nulls\n",
    "print(\"Nº ratings before removing: {}\".format(len(ratings_date.index)))\n",
    "ratings_no_nulls = remove_nulls(ratings_date)\n",
    "print(\"Nº ratings after removing: {}\".format(len(ratings_no_nulls.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ff897",
   "metadata": {},
   "source": [
    "Having removed all the completely invalid elements of our data, we want to remove values that may seem to be correct but are not in the subset of possible values: $\\{0.5\\cdot i\\}_{i=1}^{10}$ (we assume that the ratings are in this set because the [documentation](https://files.grouplens.org/datasets/movielens/ml-latest-README.html) says so). A few approaches can taken in this spot, making some assumptions in the current values of the table. For instance, we could assume that all the values hat have a negative sign (which, we have checked that they exist), either are the same values but with a positive sign or are the minimum score. Since making an interpretation on this is complicated, we decide to simply eliminate them so that we do not introduce a bias in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac835b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_evaluations(df):\n",
    "    correct_vals = np.arange(0.5, 5.01, 0.5)\n",
    "    return df[df['rating'].isin(correct_vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8108a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº ratings before removing wrong: 254432\n",
      "Nº ratings after removing wrong: 254338\n"
     ]
    }
   ],
   "source": [
    "print(\"Nº ratings before removing wrong: {}\".format(len(ratings_no_nulls.index)))\n",
    "ratings_no_wrong = remove_wrong_evaluations(ratings_no_nulls)\n",
    "print(\"Nº ratings after removing wrong: {}\".format(len(ratings_no_wrong.index)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969573c2",
   "metadata": {},
   "source": [
    "We have removed all the meaningless data. Now, our goal is to create a field on this database that will help us perform the previously mentioned query much easily. We want to create a new column in this dataframe that indicates the **average rating** of each movie in the last week. \n",
    "\n",
    "We only have to group all the elements of the final dataframe by the field `movieId`, and then compute the mean of the field `rating` for each group obtained in the grouping stage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadaadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_id = lambda df: df.groupby('movieId')['rating'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec5073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_store = mean_per_id(ratings_no_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced5e8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "0    3.541176\n",
       "1    3.984507\n",
       "2    3.541667\n",
       "3    3.300000\n",
       "4    0.500000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_store.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac146f8",
   "metadata": {},
   "source": [
    "As we can see, we obtain a `pandas.Series` where we have the average rating that each film obtained in the last $n\\_weeks$. Some films may have dissapeared, but this is **not a problem**, since if we wanted them to be in this dataframe, their score would have to be the lowest possible, and this would introduce a bias in the average score of the gender of the film.\n",
    "\n",
    "## Final Pipeline\n",
    "\n",
    "Lastly, to make the code cleaner and alike-looking to a *Pipeline*, we are going to use `sklearn.Pipeline` to compactify this process. We previously declare a lambda function that saves the dataframe to a *csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d5d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = lambda df,name : df.to_csv(name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af53b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating_pipeline = Pipeline([\n",
    "                            ('date_filter',FunctionTransformer( func = filter_date, kw_args = {'n_weeks': 120})),\n",
    "                            ('remove_nulls',FunctionTransformer(func = remove_nulls)),\n",
    "                            ('remove_wrong_evaluations',FunctionTransformer(func = remove_wrong_evaluations)),\n",
    "                            ('compute_mean_id',FunctionTransformer(func = mean_per_id)),\n",
    "                            ('save',FunctionTransformer( func = save, kw_args = {'name': \"output/avg_movie.csv\"}))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pd.read_csv(\"output/avg_movie.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c422ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.984507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId    rating\n",
       "0        0  3.541176\n",
       "1        1  3.984507\n",
       "2        2  3.541667\n",
       "3        3  3.300000\n",
       "4        4  0.500000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cdc0a",
   "metadata": {},
   "source": [
    "As we can see, we have obtained the same result in both executions, so from now on we will only use the `average_rating_pipeline` transformer.\n",
    "\n",
    "## About the removed data\n",
    "\n",
    "Let us present in tables the information that we have already shown in the previous steps.\n",
    "\n",
    "In our case, considering the $\\%$ eliminated by date is pointless, since we already know that the data stopped updating almost 2 years ago.\n",
    "We resume it in the following table.\n",
    "\n",
    "|Transformation| Before | After | $\\%$ kept |\n",
    "|--------------| -------| ------|  ------------|\n",
    "|Invalid date| 25000095 | 259911 | 1$\\%$\n",
    "|Null/duplicated| 259911 | 254783| 98$\\%$|\n",
    "|Invalid rating |254783| 254689| 99.9$\\%$ |\n",
    "\n",
    "Recall that **all this statistics are referred to the data of the last $120$ weeks, since this is the subset we are considering**.\n",
    "\n",
    "\n",
    "\n",
    "# Movies\n",
    "\n",
    "It is now time to preprocess the `movies.csv` information. In this case, the preprocessing will be different.\n",
    "\n",
    "Firstly, we already know (from the [documentation](https://files.grouplens.org/datasets/movielens/ml-latest-README.html))  that the `genres` of the films are all valid but those one listed as `(no genres listed)`, so we will have to remove those and any other null values.\n",
    "\n",
    "Secondly, the genres are provided in a `string`, where the character `|` separates the different genres of the same film. Our goal in stage will be to split the films that contain $k$ genres into $k$ entries in the table. Each new element will have the same `movieId` but will have a unique genre (one new entry for each of the $k$ genres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ac6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulls\n",
    "def remove_null_genres(df):\n",
    "    return df[df.genres != '(no genres listed)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7df1edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies before removing invalid: 62423\n",
      "Movies after removing null genres: 57361\n",
      "Movies after removing invalid entries: 57361\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies before removing invalid: {}\".format(len(movies.index)))\n",
    "movies_no_null = remove_null_genres(movies)\n",
    "print(\"Movies after removing null genres: {}\".format(len(movies_no_null.index)))\n",
    "movies_no_null = remove_nulls(movies_no_null)\n",
    "print(\"Movies after removing invalid entries: {}\".format(len(movies_no_null.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e0ba0",
   "metadata": {},
   "source": [
    "After removing the null or invalid genres, we have to split the `genre` column into the different genres creating new rows for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ea54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_genres(df):\n",
    "    df['genres'] = df['genres'].apply(lambda x : x.split(\"|\"))\n",
    "    return df.explode('genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d6e5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies shape before split genres : (57361, 3)\n",
      "Movies shape after split genres: (107245, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies shape before split genres : {}\".format(movies_no_null.shape))\n",
    "df_split = split_genres(movies_no_null)\n",
    "print(\"Movies shape after split genres: {}\".format(df_split.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ceb99",
   "metadata": {},
   "source": [
    "We can appretiate how several columns have been added. We can also show this in the first 3 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "282c2ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title     genres\n",
       "0        1  Toy Story (1995)  Adventure\n",
       "0        1  Toy Story (1995)  Animation\n",
       "0        1  Toy Story (1995)   Children"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b388a37",
   "metadata": {},
   "source": [
    "## Final pipeline\n",
    "\n",
    "As we did before, we can create a `sklearn.Pipeline` to compactify the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24880be",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_pipe = Pipeline([\n",
    "                            ('date_filter',FunctionTransformer( func = remove_null_genres)),\n",
    "                            ('remove_nulls',FunctionTransformer(func = remove_nulls)),\n",
    "                            ('split_genres',FunctionTransformer(func = split_genres)),\n",
    "                            ('save',FunctionTransformer( func = save, kw_args = {'name': \"output/split_genre.csv\"})),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3a6c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_pipe.transform(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72c9be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pipe = pd.read_csv(\"output/split_genre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03fee148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title     genres\n",
       "0        1  Toy Story (1995)  Adventure\n",
       "1        1  Toy Story (1995)  Animation\n",
       "2        1  Toy Story (1995)   Children\n",
       "3        1  Toy Story (1995)     Comedy\n",
       "4        1  Toy Story (1995)    Fantasy"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_pipe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85406b",
   "metadata": {},
   "source": [
    "## About the removed data\n",
    "\n",
    "As we can see in the outputs of the code, there are a few changes in the size of our data. We can resume it in the following table.\n",
    "\n",
    "| Transformation  | Before | After  | $\\%$ change|\n",
    "|---------------- |--------| ------ |----- |\n",
    "| Invalid genres  | 62423  | 57361  | $0.91\\%$ |\n",
    "| Null/duplicated | 57361  | 57361  | $0\\%$ |\n",
    "| Split genres    | 57361  | 107245 | 186.9 $\\%$ |\n",
    "\n",
    "There is not a big change when removing invalid genres and no change when remove null or duplicated rows. The big change here comes when we split the genres from a single row for each movie to a row for each genre of each movie.\n",
    "\n",
    "# Dealing with the new data\n",
    "\n",
    "We assume that, every day at $3.00$A.M., new data will be available for us in the `input` folder. At this time, the data must be re-processed using the code that we have developed in this notebook. For an easier application of this code, we have created a script called `preprocessing.py`, that encapsulates all the preprocessing that it is done in this notebook. \n",
    "\n",
    "We will now explain how to perform the task daily in a **Linux environment**.\n",
    "\n",
    "To execute the preprocessing each day when the new data comes, we have to use `Cron` to schedule a daily task at that time that executes this script. As an example of the `cron` file that we would have to declare in the `/etc/cron.d` folder, we could find:\n",
    "```bash\n",
    "\n",
    "# Run preprocessing.py every day at 3.00 AM\n",
    "SHELL=/bin/bash\n",
    "PATH=/home/user/MovieLens/\n",
    "\n",
    "0 3 * * * \"python preprocessing.py\"\n",
    "```\n",
    "\n",
    "# The query\n",
    "\n",
    "\n",
    "After the data has been preprocessed, we are ready to perform the desired query to obtain the sorted list of genres by rating in the last 120 weeks (remember that we do this so that we obtain any information in our preprocessing, since the last time this data was updates was more than 2 years ago). To achieve this, we have to load the preprocessed datasets and, then, perform the query using `Pandas` transformations. Recall that all the following transformations **have an equivalent done in SQL**, supossing that each dataframe is a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15b0a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_movies = pd.read_csv(\"output/split_genre.csv\")\n",
    "pre_ratings = pd.read_csv(\"output/avg_movie.csv\")\n",
    "\n",
    "# (SQL) Join both tables and then drop movieId\n",
    "df = pd.merge(pre_movies, pre_ratings, on = 'movieId').drop(\"movieId\",axis = 1)\n",
    "\n",
    "# Group by genre and compute mean of ratings\n",
    "df = pd.DataFrame(df.groupby(\"genres\")['rating'].mean()).sort_values(by=['rating'], ascending = False)\n",
    "\n",
    "# Rename column for convenience\n",
    "df = df.rename(columns={'rating': 'Last 120 Weeks Average Rating'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a572133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last 120 Weeks Average Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Film-Noir</th>\n",
       "      <td>3.597176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychological Thriller</th>\n",
       "      <td>3.563435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>3.451769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>3.428540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>3.410993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>3.333299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>3.306670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>3.262375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>3.246771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMAX</th>\n",
       "      <td>3.217749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>3.212805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>3.211524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Espionage Action</th>\n",
       "      <td>3.193313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>3.186912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>3.178372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>3.178367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>3.126044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>3.121551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>3.075556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>3.016054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>2.763636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Last 120 Weeks Average Rating\n",
       "genres                                               \n",
       "Film-Noir                                    3.597176\n",
       "Psychological Thriller                       3.563435\n",
       "War                                          3.451769\n",
       "Documentary                                  3.428540\n",
       "Animation                                    3.410993\n",
       "Musical                                      3.333299\n",
       "Drama                                        3.306670\n",
       "Crime                                        3.262375\n",
       "Western                                      3.246771\n",
       "IMAX                                         3.217749\n",
       "Children                                     3.212805\n",
       "Romance                                      3.211524\n",
       "Espionage Action                             3.193313\n",
       "Mystery                                      3.186912\n",
       "Adventure                                    3.178372\n",
       "Fantasy                                      3.178367\n",
       "Comedy                                       3.126044\n",
       "Action                                       3.121551\n",
       "Thriller                                     3.075556\n",
       "Sci-Fi                                       3.016054\n",
       "Horror                                       2.763636"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5dacf",
   "metadata": {},
   "source": [
    "As we can see, we make use of a *JOIN* and a *GROUPBY* SQL operations, and finally we compute the means of one of the columns obtained by the `GROUPBY` and sort the result of the means computation. This code can be independently executed using the `query.py` script.\n",
    "\n",
    "The `query.py` is independent of the number of weeks that have been chosen to obtain the average ratings, so it could be used in an environment where we have weekly updated data, as well as the `preprocessing.py` script could be, only changing the `n_weeks` parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
